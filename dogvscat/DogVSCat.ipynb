{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "355ab825-1a79-4851-91b5-4aace151ed1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Said\\anaconda3\\envs\\tf310\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Input\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image, UnidentifiedImageError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9fa44d-531b-431b-8649-6e407d724d6b",
   "metadata": {},
   "source": [
    "## Cleaning data\n",
    "This function clean corrupted data or data with other extension, by checking each file esxtension and veriying it, if is corrupted then remove it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5779bb95-4511-4c15-9158-633036b918b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_folder(folder):\n",
    "    deleted = 0\n",
    "    for subdir, _, files in os.walk(folder):\n",
    "        for file in files:\n",
    "            path = os.path.join(subdir, file)\n",
    "            try:\n",
    "                with Image.open(path) as img:\n",
    "                    img.verify()  \n",
    "            except (UnidentifiedImageError, OSError):\n",
    "                print(f\"Deleting corrupted image: {path}\")\n",
    "                os.remove(path)\n",
    "                deleted += 1\n",
    "    return deleted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a232f33-7b05-4245-93a8-f8e249632975",
   "metadata": {},
   "source": [
    "## Get the data\n",
    "First we want the images to be 64x64 to be easier and faster to process and analyze, we provide the path for the datasets, check the folder to see if it have corrupted data, then print to show the user, then rescale the image, use data augmentation to avoid overfitting, the create the image generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd12ac84-8d99-47ff-bc7a-623b52ee6be1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Said\\anaconda3\\envs\\tf310\\lib\\site-packages\\PIL\\TiffImagePlugin.py:950: UserWarning: Truncated File Read\n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total of image deleted in train: 0\n",
      "Total of image deleted in validation: 0\n",
      "Found 17797 images belonging to 2 classes.\n",
      "Found 5905 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "img_size = (64, 64)\n",
    "path_train = \"dataset/train\"\n",
    "path_validation = \"dataset/validation\"\n",
    "deleted_train = check_folder(path_train)\n",
    "deleted_val = check_folder(path_validation)\n",
    "print(f\"Total of image deleted in train: {deleted_train}\")\n",
    "print(f\"Total of image deleted in validation: {deleted_val}\")\n",
    "train = ImageDataGenerator(rescale=1./255, rotation_range=20, zoom_range=0.2, horizontal_flip=True)\n",
    "validation = ImageDataGenerator(rescale=1./255)\n",
    "train_gen = train.flow_from_directory(directory= path_train, target_size=img_size, batch_size=32, class_mode='binary', shuffle=True)\n",
    "validation_gen = validation.flow_from_directory(directory= path_validation, target_size=img_size, batch_size=32, class_mode='binary', shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8544152e-8095-4d01-ac9d-b51530ab0815",
   "metadata": {},
   "source": [
    "## Creation of the model\n",
    "I create a sequential model to use 3 conv2D block to filter the images, make a callback for early stopping, pool the data to reduce size a little bit, flatten all the data then make a dense layer and dropout to avoid overfitting, the output use sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24a8806b-c529-41e1-ac92-285d1cf685af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Said\\anaconda3\\envs\\tf310\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Said\\anaconda3\\envs\\tf310\\lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "callback = EarlyStopping(patience=3)\n",
    "model = Sequential([\n",
    "    Conv2D(64, 3, activation='relu', input_shape=(64, 64, 3)),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(128, 3, activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(256, 3, activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(rate=0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4555946-f112-40a1-abff-8f690fc64b2c",
   "metadata": {},
   "source": [
    "Modify the optimizer so it learn a little bit slower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c191613-8847-4ab1-a843-dcfd450adb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(learning_rate=0.0001)\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b919af0-d12a-40c2-81c8-a378172665a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "WARNING:tensorflow:From C:\\Users\\Said\\anaconda3\\envs\\tf310\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Said\\anaconda3\\envs\\tf310\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "557/557 [==============================] - 28s 49ms/step - loss: 0.6584 - accuracy: 0.5944 - val_loss: 0.5902 - val_accuracy: 0.6882\n",
      "Epoch 2/20\n",
      "557/557 [==============================] - 27s 49ms/step - loss: 0.5901 - accuracy: 0.6899 - val_loss: 0.5396 - val_accuracy: 0.7219\n",
      "Epoch 3/20\n",
      "186/557 [=========>....................] - ETA: 15s - loss: 0.5574 - accuracy: 0.7179"
     ]
    }
   ],
   "source": [
    "model.fit(train_gen, validation_data=validation_gen, epochs=20, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8491585a-49e6-42d2-9598-dabd0f075aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"dog_vs_cat_model.keras\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (TF 2.13 CPU)",
   "language": "python",
   "name": "tf310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
